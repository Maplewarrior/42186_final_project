data:
  H: 64 #40
  W: 64 #40
  channels: 3 #3
  n_classes: 18

training:
  n_epochs: 600
  batch_size: 24
  optimization:
    optimizer_name: Adam # which optimizer to use during training
    Adam:
      betas:
        - 0.9
        - 0.999
      lr: 0.001
    SGD:
      momentum: 0.9
      lr: 0.001

VAE:
  D: 128 # dimensionality of the latent space
  num_components: 10 # ! Only for MoG and VampPrior

DDPM:
  T: 500
  p_uncond: 0.1